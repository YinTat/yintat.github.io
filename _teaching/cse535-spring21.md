---
layout: single
title: "CSE 535: Theory of Optimization and Continuous Algorithms"
permalink: /teaching/cse535-spring21/
author_profile: false
---

# CSE 535: Theory of Optimization and Continuous Algorithms

The design of algorithms is traditionally a discrete endeavor. However, many advances have come from a continuous viewpoint. Typically, a continuous process, deterministic or randomized is designed (or shown) to have desirable properties, such as approaching an optimal solution or a desired distribution, and an algorithm is derived from this by appropriate discretization. In interesting and general settings, the current fastest methods are a consequence of this perspective. We will discuss several examples of algorithms for high-dimensional optimization, and use them to understand the following concepts in detail.
+ Elimination
+ Reduction
+ Geometrization
+ Sparsification
+ Acceleration
+ Decomposition

## Administrative Information:
+ Instructor: Yin Tat Lee
+ Office Hours: By appointment, email me at (yintat@<span style="display: none;">ignoreme-</span>uw.edu) 
+ I will also answer questions in Edstem.org. (will send out the link soon).
+ Lectures: Tue, Thu 10:00-11:20 at	[Zoom](https://washington.zoom.us/j/95120229931)
+ TA: Swati Padmanabhan (pswati@<span style="display: none;">ignoreme-</span>cs.washington.edu)
+ Course evaluation: 5 assignments (100%) or 1 project (100%)
+ Prerequisite: basic knowledge of algorithms, probability, linear algebra.

## Assignments

Posted and submitted via [Gradescope](https://www.gradescope.com/courses/259020).

## Class Policy
+ You may discuss assignments with others, but you must write down the solutions by yourself.
+ Assignments as well as regrade requests are to be submitted only via gradescope.
+ In general, late submissions are not accepted (the submission server closes at the deadline). Gradescope lets you overwrite previous submissions, so it is recommended to use this feature to avoid missing the submission deadline altogether.
+ We follow the standard [UW CSE policy](https://www.cs.washington.edu/academics/misconduct) for academic integrity.
+ The recitation session is optional. In these sessions, Swati will review concepts from lecture, go over details (for example, of complicated calculations) that may have been unclear/too fast during lecture.
+ The office hours are for general questions about material from the lecture and homework problems.
+ Please refer to university policies regarding [disability accommodations](http://depts.washington.edu/uwdrs/current-students/accommodations/) or [religious accommodations](https://registrar.washington.edu/staffandfaculty/religious-accommodations-policy/).


## Tentative Schedule:

### Introduction
+ Mar 30: Introduction
+ Apr 01: Introduction

### Basic Methods
+ Apr 06: Gradient Descent
+ Apr 08: Cutting Plane Methods

### Reduction
+ Apr 13: Duality
+ Apr 15: Composition

### Geometrization
+ Apr 20: Frank-Wolfe
+ Apr 22: Newton Method & L-BFG

### Homotopy Method
+ Apr 27: Interior Point Method
+ Apr 29: Robust Interior Point Method

### Decomposition
+ May 04: Cholesky Decomposition
+ May 06: Multigrid Method

### Sparsification
+ May 11: Leverage Score Sampling
+ May 13: Stochastic Gradient Descent & Variance Reduction

### Acceleration
+ May 18: Conjugate Gradient & Chebyshev Expansion
+ May 20: Accelerated Gradient Descent

### Adaptivity
+ May 25: ?????
+ May 27: ?????

### Project Presentations (Depending on Number of Projects)
+ Jun 01: Project
+ Jun 03: Project


## Related Courses:
+ [Aaron Sidford, Introduction to Optimization Theory](https://web.stanford.edu/~sidford/courses/20fa_opt_theory/fa20_opt_theory.html)
+ [Lap Chi Lau, Convexity and Optimization](https://cs.uwaterloo.ca/~lapchi/cs798/index.html)
+ [Nisheeth Vishnoi, Algorithms for Convex Optimization](https://nisheethvishnoi.wordpress.com/convex-optimization/)
+ [Jonathan Kelner, Topics in Theoretical Computer Science: An Algorithmist's Toolkit](http://stellar.mit.edu/S/course/18/sp14/18.409/index.html)
+ [Santosh Vempala, Simple Algorithms](https://algorithms2017.wordpress.com/lectures/)
+ [Sheehan Olver, Numerical Complex Analysis](http://www.maths.usyd.edu.au/u/olver/teaching/NCA/)

## Other Lecture Notes
+ [Sébastien Bubeck, Convex Optimization: Algorithms and Complexity](https://arxiv.org/abs/1405.4980)
+ [Aharon Ben-Tal and Arkadi Nemirovski, Lectures on Modern Convex Optimization](https://www2.isye.gatech.edu/~nemirovs/Lect_ModConvOpt.pdf)
+ [Stephen J. Wright, Optimization Algorithms for Data Analysis](http://www.optimization-online.org/DB_FILE/2016/12/5748.pdf)
+ [Léon Bottou, Frank E. Curtis, Jorge Nocedal. Optimization Methods for Large-Scale Machine Learning](https://arxiv.org/abs/1606.04838)

